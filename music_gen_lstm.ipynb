{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "#handle midi files\n",
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the notes from the current MIDI file (from original source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(\"midi_files_partial/*.midi\"):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notesAndRests\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "            elif isinstance(element, note.Rest): #ADDED\n",
    "                notes.append(element.name) #ADDED\n",
    "\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the sequence of notes (from original source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np.eye(n_vocab)[network_output]\n",
    "\n",
    "    return (torch.from_numpy(network_input).float(), torch.from_numpy(network_output).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    # create LSTM in the Keras way to mimic original study\n",
    "    model = nn.Sequential(\n",
    "        nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=512,\n",
    "            num_layers=3,\n",
    "            batch_first=True,\n",
    "            dropout=0.3,\n",
    "            bidirectional=False,\n",
    "        ),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, n_vocab),\n",
    "        nn.Softmax(dim=2),\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    return (model, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lstm = model[0]\n",
    "    optimizer = model[1]\n",
    "\n",
    "    network_input = torch.tensor(network_input, dtype=torch.float32)\n",
    "    \n",
    "\n",
    "    lstm.to(device)\n",
    "\n",
    "    num_epochs = 2\n",
    "    batch_size = 64\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the training data for each epoch\n",
    "        permutation = torch.randperm(network_input.shape[0])\n",
    "        network_input = network_input[permutation]\n",
    "        network_output = network_output[permutation]\n",
    "\n",
    "        for i in range(0, network_input.shape[0], batch_size):\n",
    "            # Get batch of inputs and outputs\n",
    "            \n",
    "            inputs = network_input[i:i+batch_size].to(device)\n",
    "            targets = network_output[i:i+batch_size].to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = lstm(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Print epoch loss\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "        checkpoint_path = f\"model-epoch-{epoch+1}.pt\"\n",
    "        torch.save(lstm.state_dict(), checkpoint_path)\n",
    "\n",
    "    print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network_input, network_output, n_vocab):\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    #notes = get_notes()\n",
    "\n",
    "    # get amount of pitch names\n",
    "    #n_vocab = len(set(notes))\n",
    "\n",
    "    #network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "\n",
    "    train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_notes():\n",
    "    notes = get_notes()\n",
    "\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "    return (network_input, network_output, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing midi_files_partial\\MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Chamber4_MID--AUDIO_11_R3_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Chamber5_MID--AUDIO_18_R3_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--5.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital12_MID--AUDIO_12_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital12_MID--AUDIO_12_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital12_MID--AUDIO_12_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_13_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_13_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_13_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_14_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_14_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_14_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_14_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital16_MID--AUDIO_16_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital16_MID--AUDIO_16_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_17_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_17_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_17_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_17_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_18_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_18_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_18_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--5.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--6.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital20_MID--AUDIO_20_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital20_MID--AUDIO_20_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--5.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--4.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--5.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--6.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_10_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_10_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_10_R1_2018_wav--3.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_10_R1_2018_wav--5.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_11_R1_2018_wav--1.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_11_R1_2018_wav--2.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Recital9-11_MID--AUDIO_11_R1_2018_wav--5.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert1-3_MID--AUDIO_02_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert1-3_MID--AUDIO_05_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert1-3_MID--AUDIO_07_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert10-12_MID--AUDIO_17_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert10-12_MID--AUDIO_18_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert10-12_MID--AUDIO_20_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert4-6_MID--AUDIO_08_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert4-6_MID--AUDIO_09_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert4-6_MID--AUDIO_10_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert7-9_MID--AUDIO_11_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert7-9_MID--AUDIO_15_R2_2018_wav.midi\n",
      "Parsing midi_files_partial\\MIDI-Unprocessed_Schubert7-9_MID--AUDIO_16_R2_2018_wav.midi\n"
     ]
    }
   ],
   "source": [
    "notes_figures = prepare_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsand\\AppData\\Local\\Temp\\ipykernel_20520\\2458402309.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  network_input = torch.tensor(network_input, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_network(notes_figures[\u001b[39m0\u001b[39;49m], notes_figures[\u001b[39m1\u001b[39;49m], notes_figures[\u001b[39m2\u001b[39;49m])\n",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(network_input, network_output, n_vocab)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m#notes = get_notes()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[39m# get amount of pitch names\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m#n_vocab = len(set(notes))\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[39m#network_input, network_output = prepare_sequences(notes, n_vocab)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model \u001b[39m=\u001b[39m create_network(network_input, n_vocab)\n\u001b[1;32m---> 12\u001b[0m train(model, network_input, network_output)\n",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, network_input, network_output)\u001b[0m\n\u001b[0;32m     33\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     35\u001b[0m \u001b[39m# Forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m outputs \u001b[39m=\u001b[39m lstm(inputs)\n\u001b[0;32m     37\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     38\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "train_network(notes_figures[0], notes_figures[1], notes_figures[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
